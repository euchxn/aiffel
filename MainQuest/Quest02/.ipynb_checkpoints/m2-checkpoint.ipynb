{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9390d3a2-e1cc-4c1f-bb42-c33d99ded218",
   "metadata": {},
   "source": [
    "ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd548299-8620-4a8d-a733-c571230b1660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.12/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.12/site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.12/site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.12/site-packages (4.13.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.12/site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.12/site-packages (from beautifulsoup4) (4.14.0)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.12/site-packages (6.0.2)\n",
      "Requirement already satisfied: konlpy in /opt/conda/lib/python3.12/site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from konlpy) (1.6.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.12/site-packages (from konlpy) (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.6 in /opt/conda/lib/python3.12/site-packages (from konlpy) (2.2.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from JPype1>=0.7.0->konlpy) (25.0)\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Java ì„¤ì¹˜ ë° í™˜ê²½ë³€ìˆ˜ ì„¤ì •\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/default-java'\n",
    "os.environ['PATH'] = '/usr/lib/jvm/default-java/bin:' + os.environ.get('PATH', '')\n",
    "\n",
    "# ëŒ€ì•ˆ: Java ê²½ë¡œ ìë™ ì°¾ê¸°\n",
    "result = subprocess.run(['which', 'java'], capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    java_path = result.stdout.strip()\n",
    "    java_home = java_path.replace('/bin/java', '')\n",
    "    os.environ['JAVA_HOME'] = java_home\n",
    "\n",
    "!pip install nltk\n",
    "!pip install beautifulsoup4\n",
    "!pip install lxml\n",
    "!pip install konlpy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02fe411a-f3b6-4d20-8439-425c8a512571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu noble-security InRelease [126 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu noble InRelease [256 kB]                \n",
      "Get:3 http://security.ubuntu.com/ubuntu noble-security/restricted amd64 Packages [2709 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu noble-updates InRelease [126 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu noble-backports InRelease [126 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu noble/main amd64 Packages [1808 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu noble-security/universe amd64 Packages [1170 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu noble-security/multiverse amd64 Packages [33.1 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu noble-security/main amd64 Packages [1643 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu noble/multiverse amd64 Packages [331 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu noble/restricted amd64 Packages [117 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu noble/universe amd64 Packages [19.3 MB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu noble-updates/multiverse amd64 Packages [35.9 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu noble-updates/universe amd64 Packages [1939 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu noble-updates/restricted amd64 Packages [2847 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 Packages [2007 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu noble-backports/universe amd64 Packages [33.9 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu noble-backports/main amd64 Packages [49.4 kB]\n",
      "Fetched 34.7 MB in 5s (6327 kB/s)                          \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  ca-certificates-java java-common libnspr4 libnss3 libpcsclite1\n",
      "  openjdk-11-jre-headless\n",
      "Suggested packages:\n",
      "  default-jre pcscd openjdk-11-demo openjdk-11-source libnss-mdns\n",
      "  fonts-dejavu-extra fonts-ipafont-gothic fonts-ipafont-mincho\n",
      "  fonts-wqy-microhei | fonts-wqy-zenhei fonts-indic\n",
      "The following NEW packages will be installed:\n",
      "  ca-certificates-java java-common libnspr4 libnss3 libpcsclite1\n",
      "  openjdk-11-jdk-headless openjdk-11-jre-headless\n",
      "0 upgraded, 7 newly installed, 0 to remove and 72 not upgraded.\n",
      "Need to get 118 MB of archives.\n",
      "After this operation, 263 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu noble/main amd64 ca-certificates-java all 20240118 [11.6 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu noble/main amd64 java-common all 0.75+exp1 [6798 B]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu noble/main amd64 libnspr4 amd64 2:4.35-1.1build1 [117 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu noble/main amd64 libnss3 amd64 2:3.98-1build1 [1445 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu noble/main amd64 libpcsclite1 amd64 2.0.3-1build1 [21.4 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu noble-updates/universe amd64 openjdk-11-jre-headless amd64 11.0.28+6-1ubuntu1~24.04.1 [42.3 MB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu noble-updates/universe amd64 openjdk-11-jdk-headless amd64 11.0.28+6-1ubuntu1~24.04.1 [73.7 MB]\n",
      "Fetched 118 MB in 10s (11.8 MB/s)                                              \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package ca-certificates-java.\n",
      "(Reading database ... 52749 files and directories currently installed.)\n",
      "Preparing to unpack .../0-ca-certificates-java_20240118_all.deb ...\n",
      "Unpacking ca-certificates-java (20240118) ...\n",
      "Selecting previously unselected package java-common.\n",
      "Preparing to unpack .../1-java-common_0.75+exp1_all.deb ...\n",
      "Unpacking java-common (0.75+exp1) ...\n",
      "Selecting previously unselected package libnspr4:amd64.\n",
      "Preparing to unpack .../2-libnspr4_2%3a4.35-1.1build1_amd64.deb ...\n",
      "Unpacking libnspr4:amd64 (2:4.35-1.1build1) ...\n",
      "Selecting previously unselected package libnss3:amd64.\n",
      "Preparing to unpack .../3-libnss3_2%3a3.98-1build1_amd64.deb ...\n",
      "Unpacking libnss3:amd64 (2:3.98-1build1) ...\n",
      "Selecting previously unselected package libpcsclite1:amd64.\n",
      "Preparing to unpack .../4-libpcsclite1_2.0.3-1build1_amd64.deb ...\n",
      "Unpacking libpcsclite1:amd64 (2.0.3-1build1) ...\n",
      "Selecting previously unselected package openjdk-11-jre-headless:amd64.\n",
      "Preparing to unpack .../5-openjdk-11-jre-headless_11.0.28+6-1ubuntu1~24.04.1_amd64.deb ...\n",
      "Unpacking openjdk-11-jre-headless:amd64 (11.0.28+6-1ubuntu1~24.04.1) ...\n",
      "Selecting previously unselected package openjdk-11-jdk-headless:amd64.\n",
      "Preparing to unpack .../6-openjdk-11-jdk-headless_11.0.28+6-1ubuntu1~24.04.1_amd64.deb ...\n",
      "Unpacking openjdk-11-jdk-headless:amd64 (11.0.28+6-1ubuntu1~24.04.1) ...\n",
      "Setting up java-common (0.75+exp1) ...\n",
      "Setting up libnspr4:amd64 (2:4.35-1.1build1) ...\n",
      "Setting up libpcsclite1:amd64 (2.0.3-1build1) ...\n",
      "Setting up ca-certificates-java (20240118) ...\n",
      "No JRE found. Skipping Java certificates setup.\n",
      "Setting up libnss3:amd64 (2:3.98-1build1) ...\n",
      "Setting up openjdk-11-jre-headless:amd64 (11.0.28+6-1ubuntu1~24.04.1) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
      "Processing triggers for libc-bin (2.39-0ubuntu8.4) ...\n",
      "Processing triggers for ca-certificates-java (20240118) ...\n",
      "Adding debian:ACCVRAIZ1.pem\n",
      "Adding debian:AC_RAIZ_FNMT-RCM.pem\n",
      "Adding debian:AC_RAIZ_FNMT-RCM_SERVIDORES_SEGUROS.pem\n",
      "Adding debian:ANF_Secure_Server_Root_CA.pem\n",
      "Adding debian:Actalis_Authentication_Root_CA.pem\n",
      "Adding debian:AffirmTrust_Commercial.pem\n",
      "Adding debian:AffirmTrust_Networking.pem\n",
      "Adding debian:AffirmTrust_Premium.pem\n",
      "Adding debian:AffirmTrust_Premium_ECC.pem\n",
      "Adding debian:Amazon_Root_CA_1.pem\n",
      "Adding debian:Amazon_Root_CA_2.pem\n",
      "Adding debian:Amazon_Root_CA_3.pem\n",
      "Adding debian:Amazon_Root_CA_4.pem\n",
      "Adding debian:Atos_TrustedRoot_2011.pem\n",
      "Adding debian:Atos_TrustedRoot_Root_CA_ECC_TLS_2021.pem\n",
      "Adding debian:Atos_TrustedRoot_Root_CA_RSA_TLS_2021.pem\n",
      "Adding debian:Autoridad_de_Certificacion_Firmaprofesional_CIF_A62634068.pem\n",
      "Adding debian:BJCA_Global_Root_CA1.pem\n",
      "Adding debian:BJCA_Global_Root_CA2.pem\n",
      "Adding debian:Baltimore_CyberTrust_Root.pem\n",
      "Adding debian:Buypass_Class_2_Root_CA.pem\n",
      "Adding debian:Buypass_Class_3_Root_CA.pem\n",
      "Adding debian:CA_Disig_Root_R2.pem\n",
      "Adding debian:CFCA_EV_ROOT.pem\n",
      "Adding debian:COMODO_Certification_Authority.pem\n",
      "Adding debian:COMODO_ECC_Certification_Authority.pem\n",
      "Adding debian:COMODO_RSA_Certification_Authority.pem\n",
      "Adding debian:Certainly_Root_E1.pem\n",
      "Adding debian:Certainly_Root_R1.pem\n",
      "Adding debian:Certigna.pem\n",
      "Adding debian:Certigna_Root_CA.pem\n",
      "Adding debian:Certum_EC-384_CA.pem\n",
      "Adding debian:Certum_Trusted_Network_CA.pem\n",
      "Adding debian:Certum_Trusted_Network_CA_2.pem\n",
      "Adding debian:Certum_Trusted_Root_CA.pem\n",
      "Adding debian:CommScope_Public_Trust_ECC_Root-01.pem\n",
      "Adding debian:CommScope_Public_Trust_ECC_Root-02.pem\n",
      "Adding debian:CommScope_Public_Trust_RSA_Root-01.pem\n",
      "Adding debian:CommScope_Public_Trust_RSA_Root-02.pem\n",
      "Adding debian:Comodo_AAA_Services_root.pem\n",
      "Adding debian:D-TRUST_BR_Root_CA_1_2020.pem\n",
      "Adding debian:D-TRUST_EV_Root_CA_1_2020.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_2009.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_EV_2009.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_CA.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G2.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G3.pem\n",
      "Adding debian:DigiCert_Global_Root_CA.pem\n",
      "Adding debian:DigiCert_Global_Root_G2.pem\n",
      "Adding debian:DigiCert_Global_Root_G3.pem\n",
      "Adding debian:DigiCert_High_Assurance_EV_Root_CA.pem\n",
      "Adding debian:DigiCert_TLS_ECC_P384_Root_G5.pem\n",
      "Adding debian:DigiCert_TLS_RSA4096_Root_G5.pem\n",
      "Adding debian:DigiCert_Trusted_Root_G4.pem\n",
      "Adding debian:Entrust.net_Premium_2048_Secure_Server_CA.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_EC1.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G2.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G4.pem\n",
      "Adding debian:GDCA_TrustAUTH_R5_ROOT.pem\n",
      "Adding debian:GLOBALTRUST_2020.pem\n",
      "Adding debian:GTS_Root_R1.pem\n",
      "Adding debian:GTS_Root_R2.pem\n",
      "Adding debian:GTS_Root_R3.pem\n",
      "Adding debian:GTS_Root_R4.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R4.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R5.pem\n",
      "Adding debian:GlobalSign_Root_CA.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R3.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R6.pem\n",
      "Adding debian:GlobalSign_Root_E46.pem\n",
      "Adding debian:GlobalSign_Root_R46.pem\n",
      "Adding debian:Go_Daddy_Class_2_CA.pem\n",
      "Adding debian:Go_Daddy_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:HARICA_TLS_ECC_Root_CA_2021.pem\n",
      "Adding debian:HARICA_TLS_RSA_Root_CA_2021.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_ECC_RootCA_2015.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2015.pem\n",
      "Adding debian:HiPKI_Root_CA_-_G1.pem\n",
      "Adding debian:Hongkong_Post_Root_CA_3.pem\n",
      "Adding debian:ISRG_Root_X1.pem\n",
      "Adding debian:ISRG_Root_X2.pem\n",
      "Adding debian:IdenTrust_Commercial_Root_CA_1.pem\n",
      "Adding debian:IdenTrust_Public_Sector_Root_CA_1.pem\n",
      "Adding debian:Izenpe.com.pem\n",
      "Adding debian:Microsec_e-Szigno_Root_CA_2009.pem\n",
      "Adding debian:Microsoft_ECC_Root_Certificate_Authority_2017.pem\n",
      "Adding debian:Microsoft_RSA_Root_Certificate_Authority_2017.pem\n",
      "Adding debian:NAVER_Global_Root_Certification_Authority.pem\n",
      "Adding debian:NetLock_Arany_=Class_Gold=_FÅ‘tanÃºsÃ­tvÃ¡ny.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GB_CA.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GC_CA.pem\n",
      "Adding debian:QuoVadis_Root_CA_1_G3.pem\n",
      "Adding debian:QuoVadis_Root_CA_2.pem\n",
      "Adding debian:QuoVadis_Root_CA_2_G3.pem\n",
      "Adding debian:QuoVadis_Root_CA_3.pem\n",
      "Adding debian:QuoVadis_Root_CA_3_G3.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_RSA_R2.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_RSA.pem\n",
      "Adding debian:SSL.com_TLS_ECC_Root_CA_2022.pem\n",
      "Adding debian:SSL.com_TLS_RSA_Root_CA_2022.pem\n",
      "Adding debian:SZAFIR_ROOT_CA2.pem\n",
      "Adding debian:Sectigo_Public_Server_Authentication_Root_E46.pem\n",
      "Adding debian:Sectigo_Public_Server_Authentication_Root_R46.pem\n",
      "Adding debian:SecureSign_RootCA11.pem\n",
      "Adding debian:SecureTrust_CA.pem\n",
      "Adding debian:Secure_Global_CA.pem\n",
      "Adding debian:Security_Communication_ECC_RootCA1.pem\n",
      "Adding debian:Security_Communication_RootCA2.pem\n",
      "Adding debian:Security_Communication_RootCA3.pem\n",
      "Adding debian:Security_Communication_Root_CA.pem\n",
      "Adding debian:Starfield_Class_2_CA.pem\n",
      "Adding debian:Starfield_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:Starfield_Services_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:SwissSign_Gold_CA_-_G2.pem\n",
      "Adding debian:SwissSign_Silver_CA_-_G2.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_2.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_3.pem\n",
      "Adding debian:TUBITAK_Kamu_SM_SSL_Kok_Sertifikasi_-_Surum_1.pem\n",
      "Adding debian:TWCA_Global_Root_CA.pem\n",
      "Adding debian:TWCA_Root_Certification_Authority.pem\n",
      "Adding debian:TeliaSonera_Root_CA_v1.pem\n",
      "Adding debian:Telia_Root_CA_v2.pem\n",
      "Adding debian:TrustAsia_Global_Root_CA_G3.pem\n",
      "Adding debian:TrustAsia_Global_Root_CA_G4.pem\n",
      "Adding debian:Trustwave_Global_Certification_Authority.pem\n",
      "Adding debian:Trustwave_Global_ECC_P256_Certification_Authority.pem\n",
      "Adding debian:Trustwave_Global_ECC_P384_Certification_Authority.pem\n",
      "Adding debian:TunTrust_Root_CA.pem\n",
      "Adding debian:UCA_Extended_Validation_Root.pem\n",
      "Adding debian:UCA_Global_G2_Root.pem\n",
      "Adding debian:USERTrust_ECC_Certification_Authority.pem\n",
      "Adding debian:USERTrust_RSA_Certification_Authority.pem\n",
      "Adding debian:XRamp_Global_CA_Root.pem\n",
      "Adding debian:certSIGN_ROOT_CA.pem\n",
      "Adding debian:certSIGN_Root_CA_G2.pem\n",
      "Adding debian:e-Szigno_Root_CA_2017.pem\n",
      "Adding debian:ePKI_Root_Certification_Authority.pem\n",
      "Adding debian:emSign_ECC_Root_CA_-_C3.pem\n",
      "Adding debian:emSign_ECC_Root_CA_-_G3.pem\n",
      "Adding debian:emSign_Root_CA_-_C1.pem\n",
      "Adding debian:emSign_Root_CA_-_G1.pem\n",
      "Adding debian:vTrus_ECC_Root_CA.pem\n",
      "Adding debian:vTrus_Root_CA.pem\n",
      "done.\n",
      "Setting up openjdk-11-jdk-headless:amd64 (11.0.28+6-1ubuntu1~24.04.1) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jaotc to provide /usr/bin/jaotc (jaotc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
      "update-alternatives: warning: forcing reinstallation of alternative /usr/lib/jvm/java-11-openjdk-amd64/bin/java because link group java is broken\n",
      "update-alternatives: error: error creating symbolic link '/etc/alternatives/java.dpkg-tmp': Permission denied\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update\n",
    "!sudo apt-get install -y openjdk-11-jdk-headless\n",
    "!update-alternatives --install /usr/bin/java java /usr/lib/jvm/java-11-openjdk-amd64/bin/java 1\n",
    "\n",
    "import os\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-11-openjdk-amd64'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704b26e5-0ce5-4d63-81de-1f979381bf91",
   "metadata": {},
   "source": [
    "ë°ì´í„° ë¡œë“œ ë° ë³‘í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55007849-28d1-4d76-9f2e-480b9d20c6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1098, 2)\n",
      "   class                                       conversation\n",
      "0  ì¼ë°˜ ëŒ€í™”  ì˜¤ëŠ˜ ê´œíˆ ë§ì´ ì„¸ê²Œ ë‚˜ê°”ë˜ ê²ƒ ê°™ì•„.\\nìƒí™©ì´ ê·¸ëŸ° ë‚ ì´ ìˆì§€.\\nëŒì•„ì™€ì„œ ìƒê°í•˜...\n",
      "1  ì¼ë°˜ ëŒ€í™”  ì§‘ ì •ë¦¬ë¥¼ ì¡°ê¸ˆ í–ˆë”ë‹ˆ ê³µê°„ì´ ë„“ì–´ ë³´ì´ë”ë¼.\\në²„ë¦° ê²Œ ë§ì•„?\\nì˜¤ë˜ëœ ì„œë¥˜ë‘ ì•ˆ...\n",
      "2  ì¼ë°˜ ëŒ€í™”  ì•„ì¹¨ì— ë§‘ìŒ ë•Œë¬¸ì— ê¸¸ì´ ë§ì´ ë§‰í˜”ë”ë¼.\\nê·¸ë˜ì„œ í‰ì†Œë³´ë‹¤ ì–¼ë§ˆë‚˜ ëŠ¦ì—ˆì–´?\\nëŒ€ëµ ...\n",
      "3  ì¼ë°˜ ëŒ€í™”  í† ìš”ì¼ ì˜¤ì „ì— ì„œì ì— ì‚¬ëŒë“¤ì´ ì¢€ ë§ë”ë¼.\\nê·¸ë˜ë„ ìë¦¬ í•˜ë‚˜ëŠ” ìˆì—ˆì–´?\\nì‘, ì°½...\n",
      "4  ì¼ë°˜ ëŒ€í™”  ì˜¤ëŠ˜ ì‘ì€ ì¼ í•˜ë‚˜ í•´ëƒˆì–´.\\nì˜¤, ì–´ë–¤ ê±°ì•¼?\\në¯¸ë£¨ë˜ ì¼ì„ ë“œë””ì–´ ë§ˆë¬´ë¦¬í–ˆì–´.\\...\n"
     ]
    }
   ],
   "source": [
    "# ì§€ì—°ë‹˜ ìƒì„± ë°ì´í„°\n",
    "a = pd.read_csv('/home/jovyan/work/project/AIFFEL_quest_rs/MainQuest/Quest02/data/general_dialogues_1000_contextual_full.csv').rename(columns={'dialogue': 'conversation'})\n",
    "a['class'] = 'ì¼ë°˜ ëŒ€í™”'\n",
    "a = a[['class','conversation']]\n",
    "\n",
    "# ìœ ì°¬ë‹˜ ìƒì„± ë°ì´í„°\n",
    "b = pd.read_csv('/home/jovyan/work/project/AIFFEL_quest_rs/MainQuest/Quest02/data/general_conversations.csv')\n",
    "b = b[b['class'] == \"ì¼ë°˜ ëŒ€í™”\"]\n",
    "b = b[['class','conversation']]\n",
    "\n",
    "# ë°ì´í„° í•©ì¹˜ê¸°\n",
    "train = pd.concat([a, b], axis=0, ignore_index=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52c9e094-e047-42b4-86d1-fbbf62b7d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "\n",
    "def preprocess_sentence(sentence, stop_words):\n",
    "    # 1. ì–‘ìª½ ê³µë°± ì œê±°\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    # 2. íŠ¹ìˆ˜ë¬¸ì ë° ì´ëª¨ì§€ ì œê±° (í•œê¸€, ì˜ì–´, ìˆ«ì, ê¸°ë³¸ êµ¬ë‘ì ë§Œ í—ˆìš©)\n",
    "    sentence = re.sub(r\"[^ê°€-í£0-9a-zA-Z.,!?~\\s]\", \" \", sentence)\n",
    "\n",
    "    # 3. ì—°ì†ëœ ê³µë°± í•˜ë‚˜ë¡œ ì¶•ì†Œ ë° ì¤„ ë°”ê¿ˆ ë¬´ì‹œ\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
    "    sentence = re.sub(r\"\\n\", \" \", sentence)\n",
    "\n",
    "    # 4. ë¬¸ì¥ ë¶€í˜¸ ì•ë’¤ë¡œ ê³µë°± ì¶”ê°€ (í† í° êµ¬ë¶„ì„ ìœ„í•¨)\n",
    "    sentence = re.sub(r\"([?.!,~])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'\\s{2,}', ' ', sentence)\n",
    "    \n",
    "    # í˜•íƒœì†Œ ë¶„ì„ (ë‹¨ì–´, í’ˆì‚¬)\n",
    "    include_tags = {\"Noun\", \"Verb\", \"Adjective\", \"Exclamation\", \"Adverb\"}\n",
    "    pos_tags = okt.pos(sentence, stem=True, norm=True)\n",
    "    # ì›í•˜ëŠ” í’ˆì‚¬ë§Œ ì¶”ì¶œ\n",
    "    tokens = [\n",
    "        word for word, tag in pos_tags\n",
    "        if tag in include_tags and len(word) > 1 and word not in stop_words\n",
    "    ]\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "362720cf-7d44-4958-8289-23e653503795",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = {\n",
    "    'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë“¤', 'ë°', 'ë˜ëŠ”', 'ê·¸ë¦¬ê³ ', 'í•˜ë‹¤', 'ë˜ë‹¤', 'ìˆë‹¤',\n",
    "    'ì—†ë‹¤', 'ê°™ë‹¤', 'ë‹¤ë¥´ë‹¤', 'ìˆì–´', 'ì—†ì–´', 'í•´', 'ë¼', 'ê±°', 'ê±´', 'ê²Œ',\n",
    "    'ê² ', 'ê² ë‹¤', 'ê³ ', 'ê³¤', 'êµ°', 'êµ¼', 'ê¶ˆ', 'ê¸°', 'ê¹¨', 'ê¼¬', 'ê¾¸', \n",
    "    'ë‚˜', 'ë‚˜ìš”', 'ëƒ', 'ëƒ¥', 'ë„¤', 'ë„¤ìš”', 'ë„¹', 'ë…¸', 'ë…¸ìš”', 'ëˆ„', 'ëˆ„ê°€',\n",
    "    'ë‰´', 'ë‹ˆ', 'ë‹ˆê¹Œ', 'ë‹›', 'ë‹¤', 'ë‹¤ê³ ', 'ë‹¤ë©´', 'ë‹¤ì‹œ', 'ë‹¤ìš©', 'ë‹¤ì§€',\n",
    "    'ë‹¤í•˜', 'ë‹¥', 'ë‹¹', 'ëŒ€', 'ëŒ„', 'ë”', 'ë”êµ°', 'ë”ë‹ˆ', 'ë”ë‹ˆê¹Œ', 'ë”ë¼',\n",
    "    'ë”ë¼ë„', 'ë”ë¼ê³ ', 'ë”ë¼ë©´', 'ë”ë¼ì„œ', 'ë”ë¼í•´', 'ë”ëŸ¬', 'ë”ëŸ¬ì´', 'ë”ëŸ¬ì›Œ',\n",
    "    'ë”ìš±', 'ë”ì´ìƒ', 'ë”ì´ìƒ', 'ë”ì´ìƒ', 'ë”ì¸', 'ë”ì¥', 'ë”ì¤‘', 'ë”ì§„', 'ë”ì§„ì´',\n",
    "    'ë”ì§', 'ë”ì§ì´', 'ë”ì§ì´ë‹¤', 'ë”ì§ì´ë¼', 'ë”ì§€', 'ë”ì§„', 'ë”ì§€ë§Œ', 'ë”ì§€ë§Œì´',\n",
    "    'ë”ì§€ë‹ˆ', 'ë”ì§€ë‹¤', 'ë”ì§„ë‹¤', 'ë”ì§„ë‹¤ê³ ', 'ë”ì§„ë‹¤ë©´', 'ë”ì§„ë‹¤ë©´ì„œ', 'ë”ì§„ë‹¤ë©´ì„œë„',\n",
    "    'ì', 'ìê³ ', 'ìê¸°', 'ìê¸°ë„', 'ìê¸°ë„ë¡', 'ìê¸°ë§Œ', 'ìê¸°ë§ˆë‹¤', 'ìê¸°ë¨¸', \n",
    "    'ìê¸°ì„œ', 'ìê¸°ì—', 'ìê¸°ì—ë§Œ', 'ìê¸°ì˜', 'ìê¸°ì˜ê²ƒ', 'ìê¸°ì˜ê²ƒë„', 'ìê¸°ì˜ê²ƒë„', \n",
    "    'ìê¸°ì˜ê²ƒë„ë¡', 'ìê¸°ì˜ê²ƒì²˜ëŸ¼', 'ìê¸°ì˜ê²ƒì²˜ëŸ¼ë„', 'ìê¸°ì˜ê²ƒì²˜ëŸ¼ë„ë¡', 'ìê¸°ì˜ê²ƒì²˜ëŸ¼ë„ë¡'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "595a09bf-724d-41b8-8bce-fa7d90b907c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë¬¸: ì•ˆë…•í•˜ì„¸ìš”!! ì €ëŠ” ë°ì´í„° ë¶„ì„ì„ ì¢‹ì•„í•´ìš”~~ ğŸ˜Š\n",
      "ì „ì²˜ë¦¬ ê²°ê³¼: ['ì•ˆë…•í•˜ë‹¤', 'ë°ì´í„°', 'ë¶„ì„', 'ì¢‹ì•„í•˜ë‹¤']\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = \"ì•ˆë…•í•˜ì„¸ìš”!! ì €ëŠ” ë°ì´í„° ë¶„ì„ì„ ì¢‹ì•„í•´ìš”~~ ğŸ˜Š\"\n",
    "result = preprocess_sentence(sample_sentence, stop_words)\n",
    "print(f\"ì›ë¬¸: {sample_sentence}\")\n",
    "print(f\"ì „ì²˜ë¦¬ ê²°ê³¼: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f9485051-d877-4336-881f-246170747658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 0.6936, Accuracy: 0.4991\n",
      "Epoch 2/5 - Loss: 0.6946, Accuracy: 0.4882\n",
      "Epoch 3/5 - Loss: 0.6933, Accuracy: 0.4918\n",
      "Epoch 4/5 - Loss: 0.6933, Accuracy: 0.4954\n",
      "Epoch 5/5 - Loss: 0.6933, Accuracy: 0.4791\n",
      "í•™ìŠµ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# ========== p5 ëª¨ë¸ êµ¬ì¡° ==========\n",
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self, vocab_size, word_vector_dim):\n",
    "        super(SentimentModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, word_vector_dim)\n",
    "        self.lstm = nn.LSTM(word_vector_dim, 8, batch_first=True)\n",
    "        self.fc1 = nn.Linear(8, 8)\n",
    "        self.fc2 = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, (hn, cn) = self.lstm(x)\n",
    "        x = x[:, -1, :]  # ë§ˆì§€ë§‰ LSTM ì¶œë ¥ ì‚¬ìš©\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# ========== ì–´íœ˜ ì‚¬ì „ êµ¬ì¶• ==========\n",
    "# ì „ì²´ ëŒ€í™” ë°ì´í„°ì—ì„œ í† í° ì¶”ì¶œ\n",
    "all_tokens = []\n",
    "for sentence in train['conversation']:\n",
    "    tokens = preprocess_sentence(sentence, stop_words)\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "# í† í° ë¹ˆë„ ê³„ì‚°\n",
    "from collections import Counter\n",
    "token_freq = Counter(all_tokens)\n",
    "\n",
    "# ìƒìœ„ 5000ê°œ í† í°ìœ¼ë¡œ ì–´íœ˜ ì‚¬ì „ êµ¬ì¶•\n",
    "vocab_size = 5000\n",
    "word_to_index = {'<PAD>': 0, '<UNK>': 1}\n",
    "for idx, (word, _) in enumerate(token_freq.most_common(vocab_size - 2), start=2):\n",
    "    word_to_index[word] = idx\n",
    "\n",
    "index_to_word = {idx: word for word, idx in word_to_index.items()}\n",
    "\n",
    "# ========== ë°ì´í„° ì¸ì½”ë”© ==========\n",
    "def encode_sentence(sentence, word_to_index, max_len=100):\n",
    "    tokens = preprocess_sentence(sentence, stop_words)\n",
    "    encoded = [word_to_index.get(token, 1) for token in tokens]  # 1 = <UNK>\n",
    "    \n",
    "    # íŒ¨ë”© ë˜ëŠ” ìë¥´ê¸°\n",
    "    if len(encoded) < max_len:\n",
    "        encoded = encoded + [0] * (max_len - len(encoded))\n",
    "    else:\n",
    "        encoded = encoded[:max_len]\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "# ëª¨ë“  ë¬¸ì¥ ì¸ì½”ë”©\n",
    "maxlen = 100\n",
    "X_encoded = np.array([encode_sentence(sent, word_to_index, maxlen) for sent in train['conversation']])\n",
    "X_tensor = torch.tensor(X_encoded, dtype=torch.long)\n",
    "\n",
    "# ë ˆì´ë¸” ìƒì„± (ì„ì‹œ: ë¬´ì‘ìœ„ ë ˆì´ë¸”ë¡œ í…ŒìŠ¤íŠ¸)\n",
    "# ì‹¤ì œ ë°ì´í„°ì—ì„œëŠ” ê°ì • ë¶„ë¥˜ ë ˆì´ë¸”ì„ ì‚¬ìš©í•˜ì„¸ìš”\n",
    "y_tensor = torch.randint(0, 2, (len(train),), dtype=torch.float)\n",
    "\n",
    "# ========== ëª¨ë¸ í•™ìŠµ ==========\n",
    "vocab_size = len(word_to_index)\n",
    "embedding_dim = 16\n",
    "\n",
    "model = SentimentModel(vocab_size, embedding_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# ë°ì´í„° ë¡œë”\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# í•™ìŠµ\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        predicted = (outputs.squeeze() > 0.5).float()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"í•™ìŠµ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cbd63e18-9924-4e84-b84e-3006d5ebe4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ìµœì¢… í‰ê°€ ì§€í‘œ (F1 Macro-Score í¬í•¨)\n",
      "==================================================\n",
      "F1 Macro Score: 0.3337\n",
      "Precision Macro: 0.2505\n",
      "Recall Macro: 0.5000\n",
      "\n",
      "==================================================\n",
      "ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.50      1.00      0.67       550\n",
      "    Positive       0.00      0.00      0.00       548\n",
      "\n",
      "    accuracy                           0.50      1098\n",
      "   macro avg       0.25      0.50      0.33      1098\n",
      "weighted avg       0.25      0.50      0.33      1098\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, precision_score, recall_score\n",
    "\n",
    "# ê²€ì¦ ë°ì´í„°ì…‹ì—ì„œ F1 macro-score ê³„ì‚°\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in train_loader:\n",
    "        outputs = model(inputs)\n",
    "        predicted = (outputs.squeeze() > 0.5).float()\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# F1 Macro Score ê³„ì‚°\n",
    "f1_macro = f1_score(all_labels, all_predictions, average='macro')\n",
    "precision_macro = precision_score(all_labels, all_predictions, average='macro')\n",
    "recall_macro = recall_score(all_labels, all_predictions, average='macro')\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"ìµœì¢… í‰ê°€ ì§€í‘œ (F1 Macro-Score í¬í•¨)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"F1 Macro Score: {f1_macro:.4f}\")\n",
    "print(f\"Precision Macro: {precision_macro:.4f}\")\n",
    "print(f\"Recall Macro: {recall_macro:.4f}\")\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(all_labels, all_predictions, target_names=['Negative', 'Positive']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677cdf4b-b909-407a-9c0d-0ee89d71d5db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
